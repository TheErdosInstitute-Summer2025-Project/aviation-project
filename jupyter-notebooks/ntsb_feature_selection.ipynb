{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b906d28e",
   "metadata": {},
   "source": [
    "# NTSB Feature Selection\n",
    "\n",
    "This notebook examines the rates of missingness for each value in the master NTSB dataset, as well as population for dummy variables, allowing us to pare down features which may not be likely to be useful/predictive.\n",
    "\n",
    "### Note: \n",
    "This notebook employs the **'missingno'** package, which can be installed with a \"pip install missingno\" command in your Terminal.\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7b1fdd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as mno\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "448686ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/ntsb/cleaned/master_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2f2333f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = pd.DataFrame(data.isna().sum())\n",
    "missing_pct = missing / len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0034c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mno.bar(data,sort='ascending')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb723047",
   "metadata": {},
   "source": [
    "#### Impute values\n",
    "\n",
    "Eventually when we impute values, I think we should do so __before__ dropping any columns / infrequent values of categorical variables because we may use that information in imputation even if we don't use it in modeling. E.g. if we only two occurences of a particular aircraft model, that could still be useful for imputing missing info about the aircraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "64233bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_data = data.loc[data['total_person_count'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "94501813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Aircraft_ID\n",
       "1    2210\n",
       "2      18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_data.Aircraft_ID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a008c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['unmanned'] = 1.0 *(data['total_person_count'] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5beab",
   "metadata": {},
   "source": [
    "### Drop columns we don't need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e0174997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that we've already processed and no longer need\n",
    "data.drop(columns=['Aircraft_ID', 'ev_id', 'finding_description'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8656d",
   "metadata": {},
   "source": [
    "#### Notes \n",
    "- Since we don't want to drop columns based on their frequency in the test set, this is probably a temporary measure to simplify our exploration, but we can take it out once we have a model\n",
    "- The following should be run __before__ drop infrequent values, which fills in missing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3982660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sparse_columns(data, threshold, safe_cols=None):\n",
    "    '''\n",
    "    Drops columns from data that do not contain at least a given proportion of non-empty entries\n",
    "    \n",
    "    Inputs\n",
    "        data: pandas DataFrame\n",
    "        threshold: float in [0,1], all columns with less than this proportion of non-empty entries are dropped\n",
    "        safe_cols: list of names of columns that should not be dropped even if they are below the sparsity threshold\n",
    "    Outputs\n",
    "        data: same DataFrame with appropriate columns dropped\n",
    "    '''\n",
    "    # list of columns to drop if they are too sparse\n",
    "    unsafe_cols = [col for col in data.columns if col not in safe_cols]\n",
    "\n",
    "    for col in unsafe_cols:\n",
    "        # calculate proportion of na entries in col\n",
    "        prop_na = data[col].isna().sum() / len(data)\n",
    "        \n",
    "        # drop col if the column is too sparse\n",
    "        if prop_na > 1 - threshold:\n",
    "            data.drop(columns=col, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "292306e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = drop_sparse_columns(data, 0.8, safe_cols=['damage', 'acft_category', 'acft_make', 'acft_model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b07bed2",
   "metadata": {},
   "source": [
    "### Drop infrequent values of categorical variables\n",
    "\n",
    "Note: when we go to build the model, we'll have to make sure we're dropping values based on their frequency in the training set and NOT based on their frequency in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4cf969b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_infrequent_values(data, columns, threshold):\n",
    "    '''\n",
    "    For each of the specified columns, find the values that occur with frequency lower than the threshold,\n",
    "    and replace these values and missing values by 'other/unknown'.\n",
    "    This is only intended for categorical variables\n",
    "    \n",
    "    Inputs\n",
    "        data: pandas DataFrame\n",
    "        columns: list of column names to simplify\n",
    "        threshold: float in [0,1], frequency threshold for removing \n",
    "    Outputs\n",
    "        data: pandas DataFrame\n",
    "    '''\n",
    "\n",
    "    freq_thresh = threshold * len(data)\n",
    "\n",
    "    for col in columns:\n",
    "        counts = data[col].value_counts()\n",
    "        \n",
    "        for i in counts.index:\n",
    "            if counts[i] < freq_thresh:\n",
    "                data.loc[data[col]==i, col] = 'other/unknown'\n",
    "        \n",
    "        data.loc[data[col].isna(), col] = 'other/unknown'\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "52b996a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['ev_type', 'light_cond', 'eng_type', 'certs_held', 'fixed_retractable', \n",
    "                    'second_pilot']\n",
    "\n",
    "new_data = drop_infrequent_values(data, categorical_vars, 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b3d7d3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unmanned\n",
       "0.0    16526\n",
       "1.0       13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.unmanned.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "229f4029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ev_type', 'ev_time', 'ev_year', 'ev_month', 'latitude', 'longitude',\n",
       "       'apt_dist', 'light_cond', 'wx_dew_pt', 'gust_kts', 'altimeter',\n",
       "       'ev_highest_injury', 'inj_tot_f', 'inj_tot_m', 'inj_tot_n', 'inj_tot_s',\n",
       "       'inj_tot_t', 'aircraft_count', 'event_key', 'Aircraft_Key', 'eng_type',\n",
       "       'far_part', 'damage', 'acft_fire', 'acft_expl', 'acft_make',\n",
       "       'acft_model', 'acft_category', 'homebuilt', 'num_eng',\n",
       "       'fixed_retractable', 'certs_held', 'second_pilot', 'unmanned',\n",
       "       'Fatal_count', 'Minor_count', 'None_count', 'Serious_count',\n",
       "       'total_person_count', 'injured_person_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a017d3",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9d9f33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of people onboard and the proportion in each injury level\n",
    "\n",
    "data['num_people_onboard'] = data['inj_tot_f'] + data['inj_tot_m'] + data['inj_tot_n'] + data['inj_tot_s']\n",
    "data['prop_onboard_inj'] =  (data['num_people_onboard'] - data['inj_tot_n'])/ data['num_people_onboard']\n",
    "data['prop_onboard_inj_m'] =  data['inj_tot_m'] / data['num_people_onboard']\n",
    "data['prop_onboard_inj_s'] =  data['inj_tot_s'] / data['num_people_onboard']\n",
    "data['prop_onboard_inj_f'] =  data['inj_tot_f'] / data['num_people_onboard']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
