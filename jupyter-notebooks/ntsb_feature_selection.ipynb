{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b906d28e",
   "metadata": {},
   "source": [
    "# NTSB Feature Selection\n",
    "\n",
    "This notebook examines the rates of missingness for each value in the master NTSB dataset, as well as population for dummy variables, allowing us to pare down features which may not be likely to be useful/predictive.\n",
    "\n",
    "### Note: \n",
    "This notebook employs the **'missingno'** package, which can be installed with a \"pip install missingno\" command in your Terminal.\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1fdd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import missingno as mno\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448686ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/ntsb/cleaned/master_train.csv\")\n",
    "\n",
    "data = data.loc[(data['ev_country']=='USA') & (data['ev_type']=='ACC')] # Limit to US accidents \n",
    "data.drop(columns=['ev_country', 'ev_type'], inplace=True)\n",
    "\n",
    "data = data.loc[~data['inj_tot_t'].isna()]\n",
    "## clean more : impute ground injury values\n",
    "data[['inj_f_grnd', 'inj_m_grnd', 'inj_s_grnd']]= data[['inj_f_grnd', 'inj_m_grnd', 'inj_s_grnd']].fillna(0) \n",
    "data['ground_injury_total'] = data[['inj_f_grnd', 'inj_m_grnd', 'inj_s_grnd']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5beab",
   "metadata": {},
   "source": [
    "### Drop columns we don't need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8656d",
   "metadata": {},
   "source": [
    "#### Notes \n",
    "- Since we don't want to drop columns based on their frequency in the test set, this is probably a temporary measure to simplify our exploration, but we can take it out once we have a model\n",
    "- The following should be run __before__ drop infrequent values, which fills in missing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c103236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_ground_collision 0.974\n",
      "wind_vel_kts 0.211\n",
      "owner_acft 0.425\n",
      "oprtng_cert 1.0\n",
      "oper_cert 1.0\n",
      "evacuation 1.0\n",
      "rwy_len 0.474\n",
      "rwy_width 0.475\n",
      "acft_year 0.516\n",
      "fuel_on_board 0.711\n"
     ]
    }
   ],
   "source": [
    "## Show columns where the proportion of non-empty entries is less than 0.8\n",
    "\n",
    "for col in data.columns:\n",
    "    pna = data[col].isna().sum() / len(data)\n",
    "    if pna > 0.2 :\n",
    "        print(col, round(pna,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3982660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_sparse_columns(data, threshold, safe_cols=None):\n",
    "    '''\n",
    "    Drops columns from data that do not contain at least a given proportion of non-empty entries\n",
    "    \n",
    "    Inputs\n",
    "        data: pandas DataFrame\n",
    "        threshold: float in [0,1], all columns with less than this proportion of non-empty entries are dropped\n",
    "        safe_cols: list of names of columns that should not be dropped even if they are below the sparsity threshold\n",
    "    Outputs\n",
    "        data: same DataFrame with appropriate columns dropped\n",
    "    '''\n",
    "    # list of columns to drop if they are too sparse\n",
    "    unsafe_cols = [col for col in data.columns if col not in safe_cols]\n",
    "\n",
    "    for col in unsafe_cols:\n",
    "        # calculate proportion of na entries in col\n",
    "        prop_na = data[col].isna().sum() / len(data)\n",
    "        \n",
    "        # drop col if the column is too sparse\n",
    "        if prop_na > 1 - threshold:\n",
    "            data.drop(columns=col, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292306e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = drop_sparse_columns(data, 0.8, safe_cols=['damage', 'acft_category', 'acft_make', 'acft_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e33a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already processed\n",
    "data.drop(columns=['Aircraft', 'Aircraft_Key', 'ev_id', 'finding_description'], inplace=True)\n",
    "\n",
    "# Possible data leakage\n",
    "data.drop(columns=['acft_fire', 'acft_expl'], inplace=True)\n",
    "\n",
    "# Probably not relevant (ev_time seemingly boils down to light_cond)\n",
    "data.drop(columns=['wx_dew_pt', 'type_fly', 'ev_time'], inplace=True)\n",
    "\n",
    "# (Almost) all rows have same value\n",
    "data.drop(columns=['certs_held', 'unmanned'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2922c8",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb723047",
   "metadata": {},
   "source": [
    "Eventually when we impute values, I think we should do so __before__ dropping any columns / infrequent values of categorical variables because we may use that information in imputation even if we don't use it in modeling. E.g. if we only two occurences of a particular aircraft model, that could still be useful for imputing missing info about the aircraft.\n",
    "\n",
    "#### `total_person_count`\n",
    "We have some missing data for `total_person_count`, which can mostly be calculated, but:\n",
    "1. there are a few (~10) cases where we're missing data for both aircraft in a multi-aircraft event. \n",
    "2. if `inj_tot_t` and aircraft-level counts are missing and the other event-level injury counts are 0, this does not necessarily indicate that there were only unmanned aircraft involved. It seems that the other event-level injury counts default to 0 when they are unknown, and only `inj_tot_t` is left blank in the dataset.\n",
    "\n",
    "I found the following reasons why the injury counts might be unknown:\n",
    "- Crash occurred outside of the USA --> no NTSB investigation\n",
    "- Incident and not accident --> superficial investigation\n",
    "- Aircraft damage was discovered in an inspection --> investigation could not determine whether injuries occurred\n",
    "\n",
    "#### Filtering data\n",
    "- I think we should filter out (a) events outside the USA and (b) non-accidents because of a high likelihood of sparse data. This leaves us with ~83% of the data. \n",
    "- If we do this, most of the variables now have well over 80% of the values present\n",
    "- My gut is to filter before the train-test split, but I'm not certain that's right (or that it matters)\n",
    "\n",
    "#### Other notes\n",
    "- Oddly, `gust_kts` is 100% present but `wind_vel_kts` is ~20% missing. When `wind_vel_kts` is missing, `gust_kts` is 0 more than 99% of the time, which probably means that 0 is entered by default when it's unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8f0df",
   "metadata": {},
   "source": [
    "### Imputing values\n",
    "\n",
    "Categorical\n",
    "- Target variables (does it ever make sense to impute a target variable, or should we just omit from the dataset / performance metrics?)\n",
    "  - `damage`: guess based on injury severity \n",
    "  - `ev_highest_injury`: calculate from injury counts\n",
    "- All others: 'other/unknown'\n",
    "\n",
    "Numerical\n",
    "- Calculate from other data: `total_person_count`, `Minor_count`, `None_count`, `Serious_count`, `Fatal_count`, `injured_person_count`, `ev_highest_injury`, `inj_tot_t`\n",
    "- `latitude`, `longitude`: randomly sample? (not a huge issue -- it's only 1 row)\n",
    "- `Environmental issues`, `Organizational issues`, `Personnel issues`: impute 0\n",
    "- `num_eng`: find max number of passengers on a 1-engine aircraft, impute 1 for aircraft with at most this many passengers, 2 for aircraft with more passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc6c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing `damage` value\n",
    "## Since approximately 3.9% of the entries in the damage column are missing, we choose to drop these rows.\n",
    "data = data.loc[~data['damage'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057680ac",
   "metadata": {},
   "source": [
    "### Note (C.J.)\n",
    "\n",
    "I think we want to do the above code later because we'll want to use this data for predicting injuries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55cf2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing other categorical values\n",
    "\n",
    "for col in data.columns:\n",
    "    mask = data[col].isna()\n",
    "    if any(mask) and data[col].dtype == 'object':\n",
    "        data.loc[mask,col] = data[mask][col].replace(np.nan,'other/unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42579a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing findings\n",
    "\n",
    "data[['Environmental issues', 'Organizational issues', 'Personnel issues']] = data[['Environmental issues', 'Organizational issues', 'Personnel issues']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba8497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputing total person count\n",
    "## There are only four event_key ['20080505X00589_2', '20130118X53100_2' , '20160218X94149_2', '20170913X72254_2']\n",
    "## Whatever the exact circumstances (e.g., parked at the airport or taxiing), there were no occupants in these second aircraft, as all reported injuries (inj_tot_t) are attributed to the first aircraft in each event.\n",
    "count = ['event_key', 'Fatal_count', 'Minor_count', 'None_count', 'Serious_count', 'total_person_count', 'injured_person_count','ground_injury_total', 'inj_tot_t']\n",
    "data.loc[data['total_person_count'].isna(),count] = data[data['total_person_count'].isna()][count].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4319cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[data['ntsb_no'] == 'ANC08LA095','total_seats'] = 6 ## By searching for T210\n",
    "# data.loc[data['ntsb_no'] == 'CEN09CA474','total_seats'] = 6 ## By the number of person and search (6 - 11)\n",
    "# data.loc[data['ntsb_no'] == 'WPR10LA313','total_seats'] = 4 ## By searching for DHC-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "428a8cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are typos in the total seats like this: 2500.0\n",
      "Below table shows accidents whose total seats and the number of engines are blank.\n",
      "              event_key    acft_model\n",
      "8327   20141217X43728_1           737\n",
      "8462   20150305X42958_1         MD 88\n",
      "9258   20151029X44249_1           767\n",
      "9488   20160225X92701_1        EMB145\n",
      "11493  20171219X90251_1  ERJ170-200LR\n",
      "12114  20180725X32722_1          MD88\n",
      "12714  20190304X65511_1        EMB145\n"
     ]
    }
   ],
   "source": [
    "## For aircrafts having single engine, data shows the number of seats is less than 20.\n",
    "\n",
    "## For single-engine aircraft, check the maximum number of seats.\n",
    "print('There are typos in the total seats like this:', np.max(data[data['num_eng']==1]['total_seats'].fillna(0).values))\n",
    "\n",
    "\n",
    "## Imputing value 1 into 'num_eng' if the total seats is less than 20.\n",
    "data.loc[(data['num_eng'].isna())& (data['total_seats']<=20), 'num_eng'] = data[(data['num_eng'].isna())& (data['total_seats']<=20)]['num_eng'].fillna(1)\n",
    "\n",
    "## There are only four cases both total seats and the number of engines are blank.\n",
    "## All have two engines typically.\n",
    "print('Below table shows accidents whose total seats and the number of engines are blank.')\n",
    "print(data[(data['num_eng'].isna())& (data['total_seats'].isna()) & (data['total_person_count']>20)][['event_key','acft_model']])\n",
    "\n",
    "## We checked each acft_models in the table, and all of them has typically two engines.\n",
    "data.loc[(data['num_eng'].isna())& (data['total_seats'].isna()), 'num_eng'] = data[(data['num_eng'].isna())& (data['total_seats'].isna())]['num_eng'].fillna(2)\n",
    "\n",
    "## And other cases also have two engines typically.\n",
    "data.loc[data['num_eng'].isna(), 'num_eng'] = data[data['num_eng'].isna()]['num_eng'].fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90cf06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## While the total number of seats could potentially be inferred from other data sources or looked up online, doing so would be time-consuming.\n",
    "# ## One possible way is to look at the statistics of total seats of the same(or similar) acft model.\n",
    "# plt.hist(data[(data['far_part'] == '091' )& (data['acft_make'] == 'Piper') &(data['num_eng'] == 1.0) ]['total_seats'].values)\n",
    "# np.mean(data[(data['far_part'] == '091' )& (data['acft_make'] == 'Piper') &(data['num_eng'] == 1.0) & (~data['total_seats'].isna()) ]['total_seats'].values).round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "802c2dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_seats\n"
     ]
    }
   ],
   "source": [
    "##Check whether additional imputations are needed except for the 'total_seats' column.\n",
    "\n",
    "for col in data.columns:\n",
    "    mask = data[col].isna()\n",
    "    if any(mask):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b07bed2",
   "metadata": {},
   "source": [
    "### Category reduction for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbc73bb",
   "metadata": {},
   "source": [
    "#### Manual category reduction\n",
    "\n",
    "Before we reduce infrequent values to 'other/unknown', there may be cases where we can combine categories in a more intelligent way:\n",
    "- BroadPhaseOfFlight (what happened to this variable?)\n",
    "- `acft_category`: group based on size?\n",
    "- `far_part`: would require some research\n",
    "- `light_cond`: maybe combine all conditions other than DAYL and NITE into a 'partial light' category (would have to check what all of the abbreviations mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa96c20",
   "metadata": {},
   "source": [
    "#### Automated category reduction\n",
    "\n",
    "We'll reduce categories by reassigning all categories with frequency $< \\alpha$ to 'other/unknown' (for some $\\alpha \\in [0.01, 0.05]$)\n",
    "\n",
    "Note: when we go to build the model, we'll have to make sure we're reducing categories based on their frequency in the training set and NOT based on their frequency in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b353084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing categories for BroadPhaseofFlight\n",
    "\n",
    "phase_dict = {\n",
    "    'Landing': 'Landing',\n",
    "    'Enroute': 'Air',\n",
    "    'Maneuvering': 'Air',\n",
    "    'Takeoff': 'Takeoff',\n",
    "    'Approach': 'Landing', # or 'Air'\n",
    "    'Initial Climb': 'Takeoff',\n",
    "    'Taxi': 'Ground',\n",
    "    'Standing': 'Ground',\n",
    "    'Emergency Descent': 'Air', # or 'Landing'\n",
    "    'Uncontrolled Descent': 'Air', # or 'Landing'\n",
    "    'Pushback/Tow': 'Ground',\n",
    "    'Post-Impact': 'Ground',\n",
    "    'Unknown': 'Unknown',\n",
    "    'other/unknown': 'Unknown'\n",
    "}\n",
    "\n",
    "data['BroadPhaseofFlight'] = data['BroadPhaseofFlight'].apply(lambda x: phase_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cf969b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_categories_fill_na(data, columns, threshold):\n",
    "    '''\n",
    "    For each of the specified columns, find the values that occur with frequency lower than the threshold,\n",
    "    and replace these values and missing values by 'other/unknown'.\n",
    "    This is only intended for categorical variables\n",
    "    \n",
    "    Inputs\n",
    "        data: pandas DataFrame\n",
    "        columns: list of column names to simplify\n",
    "        threshold: float in [0,1], frequency threshold for removing \n",
    "    Outputs\n",
    "        data: pandas DataFrame\n",
    "    '''\n",
    "\n",
    "    freq_thresh = threshold * len(data)\n",
    "\n",
    "    for col in columns:\n",
    "        counts = data[col].value_counts()\n",
    "        \n",
    "        for i in counts.index:\n",
    "            if counts[i] < freq_thresh:\n",
    "                data.loc[data[col]==i, col] = 'other/unknown'\n",
    "        \n",
    "        data.loc[data[col].isna(), col] = 'other/unknown'\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52b996a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['light_cond', 'eng_type', 'far_part', 'acft_make', 'acft_category',\n",
    "                    'homebuilt', 'fixed_retractable', 'second_pilot']\n",
    "# Note: intentionally omitted 'ntsb_no', 'ev_highest_injury', 'Aircraft_ID', 'event_key', \n",
    "#                               'damage', 'acft_model'\n",
    "\n",
    "data = reduce_categories_fill_na(data, categorical_vars, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90a25a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ntsb_no', 'ev_year', 'ev_month', 'latitude', 'longitude', 'apt_dist',\n",
       "       'light_cond', 'gust_kts', 'altimeter', 'ev_highest_injury',\n",
       "       'inj_f_grnd', 'inj_m_grnd', 'inj_s_grnd', 'inj_tot_f', 'inj_tot_m',\n",
       "       'inj_tot_n', 'inj_tot_s', 'inj_tot_t', 'BroadPhaseofFlight',\n",
       "       'aircraft_count', 'Aircraft_ID', 'event_key', 'eng_type', 'far_part',\n",
       "       'damage', 'acft_make', 'acft_model', 'acft_category', 'homebuilt',\n",
       "       'total_seats', 'num_eng', 'fixed_retractable', 'date_last_insp',\n",
       "       'second_pilot', 'Environmental issues', 'Organizational issues',\n",
       "       'Personnel issues', 'Fatal_count', 'Minor_count', 'None_count',\n",
       "       'Serious_count', 'total_person_count', 'injured_person_count',\n",
       "       'ground_injury_total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a017d3",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9f33b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of people onboard and the proportion in each injury level\n",
    "\n",
    "data['num_people_onboard'] = data['inj_tot_f'] + data['inj_tot_m'] + data['inj_tot_n'] + data['inj_tot_s']\n",
    "data['prop_onboard_inj'] =  (data['num_people_onboard'] - data['inj_tot_n'])/ data['num_people_onboard']\n",
    "data['prop_onboard_inj_m'] =  data['inj_tot_m'] / data['num_people_onboard']\n",
    "data['prop_onboard_inj_s'] =  data['inj_tot_s'] / data['num_people_onboard']\n",
    "data['prop_onboard_inj_f'] =  data['inj_tot_f'] / data['num_people_onboard']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
